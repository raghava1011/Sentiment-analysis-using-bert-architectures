{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f347da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/development/raghava/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b036c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "df2 = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/test.tsv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7b289f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no movement , no yuks , not much of anything</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we never really feel involved with the story ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is one of polanski 's best films</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>an often deadly boring , strange reading of a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>the problem with concept films is that if the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>safe conduct , however ambitious and well inte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>a film made with as little wit , interest , an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>but here 's the real damn it is n't funny , ei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  1\n",
       "0          no movement , no yuks , not much of anything  0\n",
       "1     a gob of drivel so sickly sweet , even the eag...  0\n",
       "2     gangs of new york is an unapologetic mess , wh...  0\n",
       "3     we never really feel involved with the story ,...  0\n",
       "4                 this is one of polanski 's best films  1\n",
       "...                                                 ... ..\n",
       "1816  an often deadly boring , strange reading of a ...  0\n",
       "1817  the problem with concept films is that if the ...  0\n",
       "1818  safe conduct , however ambitious and well inte...  0\n",
       "1819  a film made with as little wit , interest , an...  0\n",
       "1820  but here 's the real damn it is n't funny , ei...  0\n",
       "\n",
       "[1821 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809dc4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  a stirring , funny and finally transporting re...  1\n",
       "1  apparently reassembled from the cutting room f...  0\n",
       "2  they presume their audience wo n't sit still f...  0\n",
       "3  this is a visually stunning rumination on love...  1\n",
       "4  jonathan parker 's bartleby should have been t...  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74611d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84960cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1037, 18385,  1010,  6057,  1998,  2633, 18276,  2128, 16603,\n",
      "          1997,  5053,  1998,  1996,  6841,  1998,  5687,  5469,  3152,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2159, -0.1403,  0.0083,  ..., -0.1369,  0.5867,  0.2011],\n",
       "         [-0.2471,  0.2468,  0.1008,  ..., -0.1631,  0.9349, -0.0715],\n",
       "         [ 0.0558,  0.3573,  0.4140,  ..., -0.2430,  0.1770, -0.5080],\n",
       "         ...,\n",
       "         [ 0.5113,  0.3471,  0.0273,  ...,  0.3259,  0.7047, -0.3381],\n",
       "         [ 0.2807,  0.5242, -0.5708,  ...,  0.4081,  0.4943, -0.0218],\n",
       "         [ 0.8637,  0.3259, -0.1457,  ...,  0.0325, -0.4152, -0.1499]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = df.iloc[0][0]\n",
    "ids = tokenizer(input,add_special_tokens = True,return_tensors  = 'pt',padding=True,truncation=True)\n",
    "print(ids)\n",
    "output = model(**ids)\n",
    "last_layer = output.last_hidden_state\n",
    "last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7856afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df[0].apply((lambda x: tokenizer(x,add_special_tokens = True,return_tensors  = 'pt',padding = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859e0a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1037, 18385,  1010,  6057,  1998,  2633, 18276,  2128, 16603,\n",
       "          1997,  5053,  1998,  1996,  6841,  1998,  5687,  5469,  3152,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "948cc31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lis = []\n",
    "# for ele in tokenized:\n",
    "#     lis.append(len(ele['input_ids'][0]))\n",
    "# max(lis)\n",
    "max_leng = max([len(ele['input_ids'][0]) for ele in tokenized])\n",
    "max_leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02efb3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in tokenized.values:\n",
    "    pad = torch.zeros(max_leng-len(ele['input_ids'][0])).int()\n",
    "    temp = torch.cat((ele['input_ids'][0],pad),0)\n",
    "    ele['input_ids'] = temp[None,:]\n",
    "    temp = torch.cat((ele['attention_mask'][0],pad),0)\n",
    "    ele['attention_mask'] = temp[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6434d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    last = model(**tokenized[0])\n",
    "    last_h = last.last_hidden_state\n",
    "    cls = last_h[0][0]\n",
    "    for ind,ele in enumerate(tokenized):\n",
    "        if ind==0:\n",
    "            continue\n",
    "        last = model(**ele)\n",
    "        last_h = last.last_hidden_state\n",
    "        cls = torch.vstack((cls,last_h[0][0]))\n",
    "        if ind%100 == 0:\n",
    "            print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9803be33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6920, 768]),\n",
       " tensor([[-0.2159, -0.1403,  0.0083,  ..., -0.1369,  0.5867,  0.2011],\n",
       "         [-0.1726, -0.1448,  0.0022,  ..., -0.1744,  0.2139,  0.3720],\n",
       "         [-0.0506,  0.0720, -0.0296,  ..., -0.0715,  0.7185,  0.2623],\n",
       "         ...,\n",
       "         [-0.0655, -0.0518, -0.1409,  ..., -0.0645,  0.6022,  0.2135],\n",
       "         [-0.0852, -0.0487, -0.0814,  ..., -0.1359,  0.3951,  0.2289],\n",
       "         [-0.2944, -0.0923, -0.0083,  ..., -0.0516,  0.4350,  0.2889]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.shape, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fecd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this random dimensionality reduction\n",
    "# cls1 = cls[:,0:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e20d037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.21593432, -0.14028907,  0.00831073, ..., -0.13694835,\n",
       "          0.58670044,  0.20112701],\n",
       "        [-0.17262723, -0.14476171,  0.00223433, ..., -0.17442548,\n",
       "          0.21386431,  0.3719748 ],\n",
       "        [-0.05063358,  0.07203972, -0.02959727, ..., -0.07148945,\n",
       "          0.718524  ,  0.26225477],\n",
       "        ...,\n",
       "        [-0.06550945, -0.05184749, -0.14094478, ..., -0.0645067 ,\n",
       "          0.6022304 ,  0.21347874],\n",
       "        [-0.08523133, -0.04869818, -0.08137523, ..., -0.1358935 ,\n",
       "          0.39505628,  0.22889718],\n",
       "        [-0.2943684 , -0.09234691, -0.00831687, ..., -0.0515911 ,\n",
       "          0.43497857,  0.2889159 ]], dtype=float32),\n",
       " (6920, 768))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = cls.numpy()\n",
    "features,features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a16f953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "6915    1\n",
       "6916    0\n",
       "6917    0\n",
       "6918    0\n",
       "6919    1\n",
       "Name: 1, Length: 6920, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcbda118",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft,test_ft, train_lb, test_lb = train_test_split(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4725b9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/development/raghava/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_ft, train_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7146355a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502890173410405"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_ft,test_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f632ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
